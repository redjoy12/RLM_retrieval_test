# RLM Document Retrieval System - Environment Configuration

# LLM Configuration (LiteLLM supports 100+ providers)
# Examples: openai, anthropic, azure, google, ollama, vllm, etc.
RLM_LITELLM_PROVIDER=openai
RLM_DEFAULT_MODEL=gpt-5-mini

# API Keys (set the one for your provider)
OPENAI_API_KEY=your-openai-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here
# AZURE_API_KEY=your-azure-key-here
# AZURE_API_BASE=your-azure-endpoint-here
# GOOGLE_API_KEY=your-google-key-here

# Optional: Custom API base URL
# RLM_LITELLM_API_BASE=https://custom-api-endpoint.com/v1

# Recursion Limits
RLM_MAX_RECURSION_DEPTH=3
RLM_MAX_SUB_LLM_CALLS=100

# Timeouts (seconds)
RLM_CODE_EXECUTION_TIMEOUT=30
RLM_LLM_TIMEOUT=60

# Context Handling (for 10M+ token support)
RLM_CONTEXT_CHUNK_SIZE=100000
RLM_MAX_CONTEXT_CHUNKS_IN_MEMORY=10

# Sandbox Settings
RLM_SANDBOX_OUTPUT_LIMIT=8192
RLM_SANDBOX_MEMORY_LIMIT_MB=512

# Logging
RLM_LOG_LEVEL=INFO
RLM_LOG_DIR=./logs
RLM_ENABLE_TRAJECTORY_LOGGING=true

# API Server
RLM_API_HOST=0.0.0.0
RLM_API_PORT=8000
